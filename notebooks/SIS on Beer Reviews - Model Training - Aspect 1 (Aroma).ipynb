{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIS on Beer Reviews - Model Training Aspect 1 (Aroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, verbose=True):\n",
    "    data_x, data_y = [ ], [ ]\n",
    "    fopen = gzip.open if path.endswith(\".gz\") else open\n",
    "    with fopen(path) as fin:\n",
    "        for line in fin:\n",
    "            line = line.decode('ascii')\n",
    "            y, sep, x = line.partition(\"\\t\")\n",
    "            # x = x.split()\n",
    "            y = y.split()\n",
    "            if len(x) == 0: continue\n",
    "            y = np.asarray([ float(v) for v in y ])\n",
    "            data_x.append(x)\n",
    "            data_y.append(y)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{} examples loaded from {}\".format(len(data_x), path))\n",
    "        print(\"max text length: {}\".format(max(len(x) for x in data_x)))\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 examples loaded from ../data/beer_reviews/reviews.aspect1.train.txt.gz\n",
      "max text length: 5085\n",
      "10000 examples loaded from ../data/beer_reviews/reviews.aspect1.heldout.txt.gz\n",
      "max text length: 4619\n"
     ]
    }
   ],
   "source": [
    "# Load beer review data for a particular aspect\n",
    "\n",
    "ASPECT = 1  # 1, 2, or 3\n",
    "\n",
    "BASE_PATH = '../data/beer_reviews'\n",
    "\n",
    "path = os.path.join(BASE_PATH, 'reviews.aspect' + str(ASPECT))\n",
    "train_path = path + '.train.txt.gz'\n",
    "heldout_path = path + '.heldout.txt.gz'\n",
    "\n",
    "X_train_texts, y_train = load_reviews(train_path)\n",
    "X_test_texts, y_test = load_reviews(heldout_path)\n",
    "\n",
    "# y value is just the sentiment for this aspect, throw away the other scores\n",
    "y_train = np.array([y[ASPECT] for y in y_train])\n",
    "y_test = np.array([y[ASPECT] for y in y_test])\n",
    "\n",
    "# Create a 3k validation set held-out from the test set\n",
    "X_test_texts, X_val_texts, y_test, y_val = train_test_split(\n",
    "                                                X_test_texts,\n",
    "                                                y_test,\n",
    "                                                test_size=3000,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.680\n",
      "Median: 0.700\n",
      "Stdev: 0.238\n",
      "Review length:\n",
      "Mean 154.47 words (stddev: 81.134751)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "\n",
    "print('Mean: %.3f' % np.mean(y_train))\n",
    "print('Median: %.3f' % np.median(y_train))\n",
    "print('Stdev: %.3f' % np.std(y_train))\n",
    "\n",
    "print('Review length:')\n",
    "train_texts_lengths = [len(x.split(' ')) for x in X_train_texts]\n",
    "print(\"Mean %.2f words (stddev: %f)\" % \\\n",
    "      (np.mean(train_texts_lengths),\n",
    "       np.std(train_texts_lengths)))\n",
    "\n",
    "# plot review lengths\n",
    "plt.boxplot(train_texts_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "3000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the texts and keep only the top n words\n",
    "\n",
    "TOP_WORDS = 10000\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=TOP_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_texts)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train_texts)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_texts)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_texts)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bound reviews at 500 words, truncating longer reviews and zero-padding shorter reviews\n",
    "\n",
    "MAX_WORDS = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=MAX_WORDS)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=MAX_WORDS)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_token = {tokenizer.word_index[k]: k for k in tokenizer.word_index.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination_metric(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 500, 200)          240800    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,561,801\n",
      "Trainable params: 1,561,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 70000 samples, validate on 3000 samples\n",
      "Epoch 1/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0472 - mean_squared_error: 0.0472 - mean_absolute_error: 0.1838 - coeff_determination_metric: 0.1582\n",
      "Epoch 00001: val_loss improved from inf to 0.04676, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.01-0.0468.hdf5\n",
      "70000/70000 [==============================] - 914s 13ms/step - loss: 0.0472 - mean_squared_error: 0.0472 - mean_absolute_error: 0.1838 - coeff_determination_metric: 0.1582 - val_loss: 0.0468 - val_mean_squared_error: 0.0468 - val_mean_absolute_error: 0.1789 - val_coeff_determination_metric: 0.1707\n",
      "Epoch 2/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0476 - mean_squared_error: 0.0476 - mean_absolute_error: 0.1873 - coeff_determination_metric: 0.1515\n",
      "Epoch 00002: val_loss improved from 0.04676 to 0.03574, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.02-0.0357.hdf5\n",
      "70000/70000 [==============================] - 941s 13ms/step - loss: 0.0476 - mean_squared_error: 0.0476 - mean_absolute_error: 0.1873 - coeff_determination_metric: 0.1520 - val_loss: 0.0357 - val_mean_squared_error: 0.0357 - val_mean_absolute_error: 0.1528 - val_coeff_determination_metric: 0.3671\n",
      "Epoch 3/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0341 - mean_squared_error: 0.0341 - mean_absolute_error: 0.1496 - coeff_determination_metric: 0.3920\n",
      "Epoch 00003: val_loss improved from 0.03574 to 0.02953, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.03-0.0295.hdf5\n",
      "70000/70000 [==============================] - 932s 13ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - mean_absolute_error: 0.1496 - coeff_determination_metric: 0.3922 - val_loss: 0.0295 - val_mean_squared_error: 0.0295 - val_mean_absolute_error: 0.1352 - val_coeff_determination_metric: 0.4773\n",
      "Epoch 4/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0283 - mean_squared_error: 0.0283 - mean_absolute_error: 0.1336 - coeff_determination_metric: 0.4944\n",
      "Epoch 00004: val_loss improved from 0.02953 to 0.02749, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.04-0.0275.hdf5\n",
      "70000/70000 [==============================] - 905s 13ms/step - loss: 0.0283 - mean_squared_error: 0.0283 - mean_absolute_error: 0.1336 - coeff_determination_metric: 0.4944 - val_loss: 0.0275 - val_mean_squared_error: 0.0275 - val_mean_absolute_error: 0.1316 - val_coeff_determination_metric: 0.5129\n",
      "Epoch 5/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0235 - mean_squared_error: 0.0235 - mean_absolute_error: 0.1190 - coeff_determination_metric: 0.5792\n",
      "Epoch 00005: val_loss improved from 0.02749 to 0.02519, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.05-0.0252.hdf5\n",
      "70000/70000 [==============================] - 916s 13ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - mean_absolute_error: 0.1190 - coeff_determination_metric: 0.5791 - val_loss: 0.0252 - val_mean_squared_error: 0.0252 - val_mean_absolute_error: 0.1246 - val_coeff_determination_metric: 0.5536\n",
      "Epoch 6/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0203 - mean_squared_error: 0.0203 - mean_absolute_error: 0.1093 - coeff_determination_metric: 0.6369\n",
      "Epoch 00006: val_loss improved from 0.02519 to 0.02454, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.06-0.0245.hdf5\n",
      "70000/70000 [==============================] - 899s 13ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - mean_absolute_error: 0.1093 - coeff_determination_metric: 0.6368 - val_loss: 0.0245 - val_mean_squared_error: 0.0245 - val_mean_absolute_error: 0.1194 - val_coeff_determination_metric: 0.5648\n",
      "Epoch 7/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0181 - mean_squared_error: 0.0181 - mean_absolute_error: 0.1023 - coeff_determination_metric: 0.6764\n",
      "Epoch 00007: val_loss improved from 0.02454 to 0.02454, saving model to ../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.07-0.0245.hdf5\n",
      "70000/70000 [==============================] - 901s 13ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - mean_absolute_error: 0.1023 - coeff_determination_metric: 0.6764 - val_loss: 0.0245 - val_mean_squared_error: 0.0245 - val_mean_absolute_error: 0.1188 - val_coeff_determination_metric: 0.5651\n",
      "Epoch 8/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0164 - mean_squared_error: 0.0164 - mean_absolute_error: 0.0967 - coeff_determination_metric: 0.7070\n",
      "Epoch 00008: val_loss did not improve\n",
      "70000/70000 [==============================] - 943s 13ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - mean_absolute_error: 0.0967 - coeff_determination_metric: 0.7070 - val_loss: 0.0247 - val_mean_squared_error: 0.0247 - val_mean_absolute_error: 0.1188 - val_coeff_determination_metric: 0.5615\n",
      "Epoch 9/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0150 - mean_squared_error: 0.0150 - mean_absolute_error: 0.0918 - coeff_determination_metric: 0.7324\n",
      "Epoch 00009: val_loss did not improve\n",
      "70000/70000 [==============================] - 913s 13ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - mean_absolute_error: 0.0918 - coeff_determination_metric: 0.7323 - val_loss: 0.0252 - val_mean_squared_error: 0.0252 - val_mean_absolute_error: 0.1180 - val_coeff_determination_metric: 0.5536\n",
      "Epoch 10/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0867 - coeff_determination_metric: 0.7583\n",
      "Epoch 00010: val_loss did not improve\n",
      "70000/70000 [==============================] - 880s 13ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0867 - coeff_determination_metric: 0.7583 - val_loss: 0.0247 - val_mean_squared_error: 0.0247 - val_mean_absolute_error: 0.1158 - val_coeff_determination_metric: 0.5615\n",
      "Epoch 11/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0123 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0822 - coeff_determination_metric: 0.7805\n",
      "Epoch 00011: val_loss did not improve\n",
      "70000/70000 [==============================] - 835s 12ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0822 - coeff_determination_metric: 0.7806 - val_loss: 0.0264 - val_mean_squared_error: 0.0264 - val_mean_absolute_error: 0.1178 - val_coeff_determination_metric: 0.5307\n",
      "Epoch 12/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0110 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0776 - coeff_determination_metric: 0.8027\n",
      "Epoch 00012: val_loss did not improve\n",
      "70000/70000 [==============================] - 836s 12ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0776 - coeff_determination_metric: 0.8027 - val_loss: 0.0261 - val_mean_squared_error: 0.0261 - val_mean_absolute_error: 0.1157 - val_coeff_determination_metric: 0.5364\n",
      "Epoch 13/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0101 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0739 - coeff_determination_metric: 0.8201\n",
      "Epoch 00013: val_loss did not improve\n",
      "70000/70000 [==============================] - 844s 12ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0739 - coeff_determination_metric: 0.8201 - val_loss: 0.0265 - val_mean_squared_error: 0.0265 - val_mean_absolute_error: 0.1161 - val_coeff_determination_metric: 0.5288\n",
      "Epoch 14/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0092 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0704 - coeff_determination_metric: 0.8351\n",
      "Epoch 00014: val_loss did not improve\n",
      "70000/70000 [==============================] - 896s 13ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0704 - coeff_determination_metric: 0.8349 - val_loss: 0.0282 - val_mean_squared_error: 0.0282 - val_mean_absolute_error: 0.1177 - val_coeff_determination_metric: 0.4998\n",
      "Epoch 15/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0085 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0673 - coeff_determination_metric: 0.8481\n",
      "Epoch 00015: val_loss did not improve\n",
      "70000/70000 [==============================] - 893s 13ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0674 - coeff_determination_metric: 0.8481 - val_loss: 0.0273 - val_mean_squared_error: 0.0273 - val_mean_absolute_error: 0.1160 - val_coeff_determination_metric: 0.5167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2060dfef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM 200\n",
    "def make_lstm_model(top_words, max_words):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, 100, input_length=max_words))\n",
    "    model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['mse', 'mae', coeff_determination_metric])\n",
    "    return model\n",
    "\n",
    "model = make_lstm_model(TOP_WORDS, MAX_WORDS)\n",
    "print(model.summary())\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../trained_models/asp1.regress.bs128.nodrop.lstm200.100dimembed.weights.{epoch:02d}-{val_loss:.4f}.hdf5',\n",
    "                               verbose=1,\n",
    "                               monitor='val_loss',\n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=15,\n",
    "          batch_size=128,\n",
    "          callbacks=[checkpointer],\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
