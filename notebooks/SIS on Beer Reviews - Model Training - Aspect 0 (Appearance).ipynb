{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIS on Beer Reviews - Model Training Aspect 0 (Appearance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, verbose=True):\n",
    "    data_x, data_y = [ ], [ ]\n",
    "    fopen = gzip.open if path.endswith(\".gz\") else open\n",
    "    with fopen(path) as fin:\n",
    "        for line in fin:\n",
    "            line = line.decode('ascii')\n",
    "            y, sep, x = line.partition(\"\\t\")\n",
    "            # x = x.split()\n",
    "            y = y.split()\n",
    "            if len(x) == 0: continue\n",
    "            y = np.asarray([ float(v) for v in y ])\n",
    "            data_x.append(x)\n",
    "            data_y.append(y)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{} examples loaded from {}\".format(len(data_x), path))\n",
    "        print(\"max text length: {}\".format(max(len(x) for x in data_x)))\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 examples loaded from ../data/beer_reviews/reviews.aspect0.train.txt.gz\n",
      "max text length: 5113\n",
      "10000 examples loaded from ../data/beer_reviews/reviews.aspect0.heldout.txt.gz\n",
      "max text length: 4999\n"
     ]
    }
   ],
   "source": [
    "# Load beer review data for a particular aspect\n",
    "\n",
    "ASPECT = 0  # 0, 1, 2, or 3\n",
    "\n",
    "BASE_PATH = '../data/beer_reviews'\n",
    "\n",
    "path = os.path.join(BASE_PATH, 'reviews.aspect' + str(ASPECT))\n",
    "train_path = path + '.train.txt.gz'\n",
    "heldout_path = path + '.heldout.txt.gz'\n",
    "\n",
    "X_train_texts, y_train = load_reviews(train_path)\n",
    "X_test_texts, y_test = load_reviews(heldout_path)\n",
    "\n",
    "# y value is just the sentiment for this aspect, throw away the other scores\n",
    "y_train = np.array([y[ASPECT] for y in y_train])\n",
    "y_test = np.array([y[ASPECT] for y in y_test])\n",
    "\n",
    "# Create a 3k validation set held-out from the test set\n",
    "X_test_texts, X_val_texts, y_test, y_val = train_test_split(\n",
    "                                                X_test_texts,\n",
    "                                                y_test,\n",
    "                                                test_size=3000,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.697\n",
      "Median: 0.700\n",
      "Stdev: 0.252\n",
      "Review length:\n",
      "Mean 152.06 words (stddev: 82.575202)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "\n",
    "print('Mean: %.3f' % np.mean(y_train))\n",
    "print('Median: %.3f' % np.median(y_train))\n",
    "print('Stdev: %.3f' % np.std(y_train))\n",
    "\n",
    "print('Review length:')\n",
    "train_texts_lengths = [len(x.split(' ')) for x in X_train_texts]\n",
    "print(\"Mean %.2f words (stddev: %f)\" % \\\n",
    "      (np.mean(train_texts_lengths),\n",
    "       np.std(train_texts_lengths)))\n",
    "\n",
    "# plot review lengths\n",
    "plt.boxplot(train_texts_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "3000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the texts and keep only the top n words\n",
    "\n",
    "TOP_WORDS = 10000\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=TOP_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_texts)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train_texts)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_texts)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_texts)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bound reviews at 500 words, truncating longer reviews and zero-padding shorter reviews\n",
    "\n",
    "MAX_WORDS = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=MAX_WORDS)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=MAX_WORDS)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_token = {tokenizer.word_index[k]: k for k in tokenizer.word_index.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination_metric(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500, 200)          240800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,561,801\n",
      "Trainable params: 1,561,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 80000 samples, validate on 3000 samples\n",
      "Epoch 1/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0578 - mean_squared_error: 0.0578 - mean_absolute_error: 0.2138 - coeff_determination_metric: 0.0828\n",
      "Epoch 00001: val_loss improved from inf to 0.05262, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.01-0.0526.hdf5\n",
      "80000/80000 [==============================] - 994s 12ms/step - loss: 0.0578 - mean_squared_error: 0.0578 - mean_absolute_error: 0.2138 - coeff_determination_metric: 0.0826 - val_loss: 0.0526 - val_mean_squared_error: 0.0526 - val_mean_absolute_error: 0.2057 - val_coeff_determination_metric: 0.1508\n",
      "Epoch 2/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0500 - mean_squared_error: 0.0500 - mean_absolute_error: 0.1942 - coeff_determination_metric: 0.2046\n",
      "Epoch 00002: val_loss improved from 0.05262 to 0.04014, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.02-0.0401.hdf5\n",
      "80000/80000 [==============================] - 955s 12ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - mean_absolute_error: 0.1941 - coeff_determination_metric: 0.2050 - val_loss: 0.0401 - val_mean_squared_error: 0.0401 - val_mean_absolute_error: 0.1654 - val_coeff_determination_metric: 0.3517\n",
      "Epoch 3/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0404 - mean_squared_error: 0.0404 - mean_absolute_error: 0.1635 - coeff_determination_metric: 0.3581\n",
      "Epoch 00003: val_loss improved from 0.04014 to 0.03351, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.03-0.0335.hdf5\n",
      "80000/80000 [==============================] - 952s 12ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - mean_absolute_error: 0.1634 - coeff_determination_metric: 0.3583 - val_loss: 0.0335 - val_mean_squared_error: 0.0335 - val_mean_absolute_error: 0.1370 - val_coeff_determination_metric: 0.4572\n",
      "Epoch 4/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0284 - mean_squared_error: 0.0284 - mean_absolute_error: 0.1297 - coeff_determination_metric: 0.5477\n",
      "Epoch 00004: val_loss improved from 0.03351 to 0.02675, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.04-0.0267.hdf5\n",
      "80000/80000 [==============================] - 952s 12ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - mean_absolute_error: 0.1297 - coeff_determination_metric: 0.5477 - val_loss: 0.0267 - val_mean_squared_error: 0.0267 - val_mean_absolute_error: 0.1254 - val_coeff_determination_metric: 0.5680\n",
      "Epoch 5/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0269 - mean_squared_error: 0.0269 - mean_absolute_error: 0.1255 - coeff_determination_metric: 0.5722\n",
      "Epoch 00005: val_loss improved from 0.02675 to 0.02575, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.05-0.0258.hdf5\n",
      "80000/80000 [==============================] - 952s 12ms/step - loss: 0.0269 - mean_squared_error: 0.0269 - mean_absolute_error: 0.1255 - coeff_determination_metric: 0.5722 - val_loss: 0.0258 - val_mean_squared_error: 0.0258 - val_mean_absolute_error: 0.1225 - val_coeff_determination_metric: 0.5835\n",
      "Epoch 6/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0229 - mean_squared_error: 0.0229 - mean_absolute_error: 0.1131 - coeff_determination_metric: 0.6348\n",
      "Epoch 00006: val_loss improved from 0.02575 to 0.02494, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.06-0.0249.hdf5\n",
      "80000/80000 [==============================] - 952s 12ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - mean_absolute_error: 0.1131 - coeff_determination_metric: 0.6348 - val_loss: 0.0249 - val_mean_squared_error: 0.0249 - val_mean_absolute_error: 0.1185 - val_coeff_determination_metric: 0.5968\n",
      "Epoch 7/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0207 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1059 - coeff_determination_metric: 0.6692\n",
      "Epoch 00007: val_loss improved from 0.02494 to 0.02480, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.07-0.0248.hdf5\n",
      "80000/80000 [==============================] - 951s 12ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1059 - coeff_determination_metric: 0.6692 - val_loss: 0.0248 - val_mean_squared_error: 0.0248 - val_mean_absolute_error: 0.1193 - val_coeff_determination_metric: 0.5991\n",
      "Epoch 8/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0187 - mean_squared_error: 0.0187 - mean_absolute_error: 0.0992 - coeff_determination_metric: 0.7010\n",
      "Epoch 00008: val_loss improved from 0.02480 to 0.02430, saving model to ../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.08-0.0243.hdf5\n",
      "80000/80000 [==============================] - 953s 12ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - mean_absolute_error: 0.0992 - coeff_determination_metric: 0.7008 - val_loss: 0.0243 - val_mean_squared_error: 0.0243 - val_mean_absolute_error: 0.1139 - val_coeff_determination_metric: 0.6074\n",
      "Epoch 9/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0169 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0927 - coeff_determination_metric: 0.7304\n",
      "Epoch 00009: val_loss did not improve\n",
      "80000/80000 [==============================] - 951s 12ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0927 - coeff_determination_metric: 0.7304 - val_loss: 0.0247 - val_mean_squared_error: 0.0247 - val_mean_absolute_error: 0.1117 - val_coeff_determination_metric: 0.5993\n",
      "Epoch 10/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0154 - mean_squared_error: 0.0154 - mean_absolute_error: 0.0875 - coeff_determination_metric: 0.7551\n",
      "Epoch 00010: val_loss did not improve\n",
      "80000/80000 [==============================] - 956s 12ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - mean_absolute_error: 0.0875 - coeff_determination_metric: 0.7551 - val_loss: 0.0250 - val_mean_squared_error: 0.0250 - val_mean_absolute_error: 0.1103 - val_coeff_determination_metric: 0.5952\n",
      "Epoch 11/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0139 - mean_squared_error: 0.0139 - mean_absolute_error: 0.0823 - coeff_determination_metric: 0.7782\n",
      "Epoch 00011: val_loss did not improve\n",
      "80000/80000 [==============================] - 952s 12ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - mean_absolute_error: 0.0823 - coeff_determination_metric: 0.7782 - val_loss: 0.0253 - val_mean_squared_error: 0.0253 - val_mean_absolute_error: 0.1101 - val_coeff_determination_metric: 0.5902\n",
      "Epoch 12/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0126 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0776 - coeff_determination_metric: 0.7993\n",
      "Epoch 00012: val_loss did not improve\n",
      "80000/80000 [==============================] - 952s 12ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0776 - coeff_determination_metric: 0.7993 - val_loss: 0.0258 - val_mean_squared_error: 0.0258 - val_mean_absolute_error: 0.1106 - val_coeff_determination_metric: 0.5829\n",
      "Epoch 13/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0115 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0736 - coeff_determination_metric: 0.8166\n",
      "Epoch 00013: val_loss did not improve\n",
      "80000/80000 [==============================] - 970s 12ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0737 - coeff_determination_metric: 0.8166 - val_loss: 0.0265 - val_mean_squared_error: 0.0265 - val_mean_absolute_error: 0.1108 - val_coeff_determination_metric: 0.5716\n",
      "Epoch 14/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0106 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0702 - coeff_determination_metric: 0.8312\n",
      "Epoch 00014: val_loss did not improve\n",
      "80000/80000 [==============================] - 956s 12ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0702 - coeff_determination_metric: 0.8312 - val_loss: 0.0271 - val_mean_squared_error: 0.0271 - val_mean_absolute_error: 0.1106 - val_coeff_determination_metric: 0.5607\n",
      "Epoch 15/15\n",
      "79872/80000 [============================>.] - ETA: 1s - loss: 0.0098 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0674 - coeff_determination_metric: 0.8441\n",
      "Epoch 00015: val_loss did not improve\n",
      "80000/80000 [==============================] - 965s 12ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0674 - coeff_determination_metric: 0.8441 - val_loss: 0.0274 - val_mean_squared_error: 0.0274 - val_mean_absolute_error: 0.1109 - val_coeff_determination_metric: 0.5554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd820ee48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM200 model\n",
    "\n",
    "def make_lstm_model(top_words, max_words):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, 100, input_length=max_words))\n",
    "    model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['mse', 'mae', coeff_determination_metric])\n",
    "    return model\n",
    "\n",
    "model = make_lstm_model(TOP_WORDS, MAX_WORDS)\n",
    "print(model.summary())\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../trained_models/asp0.regress.bs128.nodrop.lstm200.100dimembed.weights.{epoch:02d}-{val_loss:.4f}.hdf5',\n",
    "                               verbose=1,\n",
    "                               monitor='val_loss',\n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=15,\n",
    "          batch_size=128,\n",
    "          callbacks=[checkpointer],\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
