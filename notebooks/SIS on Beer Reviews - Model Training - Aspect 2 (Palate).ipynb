{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIS on Beer Reviews - Model Training Aspect 2 (Palate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, verbose=True):\n",
    "    data_x, data_y = [ ], [ ]\n",
    "    fopen = gzip.open if path.endswith(\".gz\") else open\n",
    "    with fopen(path) as fin:\n",
    "        for line in fin:\n",
    "            line = line.decode('ascii')\n",
    "            y, sep, x = line.partition(\"\\t\")\n",
    "            # x = x.split()\n",
    "            y = y.split()\n",
    "            if len(x) == 0: continue\n",
    "            y = np.asarray([ float(v) for v in y ])\n",
    "            data_x.append(x)\n",
    "            data_y.append(y)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{} examples loaded from {}\".format(len(data_x), path))\n",
    "        print(\"max text length: {}\".format(max(len(x) for x in data_x)))\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 examples loaded from ../data/beer_reviews/reviews.aspect2.train.txt.gz\n",
      "max text length: 5085\n",
      "10000 examples loaded from ../data/beer_reviews/reviews.aspect2.heldout.txt.gz\n",
      "max text length: 4466\n"
     ]
    }
   ],
   "source": [
    "# Load beer review data for a particular aspect\n",
    "\n",
    "ASPECT = 2  # 1, 2, or 3\n",
    "\n",
    "BASE_PATH = '../data/beer_reviews/'\n",
    "\n",
    "path = os.path.join(BASE_PATH, 'reviews.aspect' + str(ASPECT))\n",
    "train_path = path + '.train.txt.gz'\n",
    "heldout_path = path + '.heldout.txt.gz'\n",
    "\n",
    "X_train_texts, y_train = load_reviews(train_path)\n",
    "X_test_texts, y_test = load_reviews(heldout_path)\n",
    "\n",
    "# y value is just the sentiment for this aspect, throw away the other scores\n",
    "y_train = np.array([y[ASPECT] for y in y_train])\n",
    "y_test = np.array([y[ASPECT] for y in y_test])\n",
    "\n",
    "# Create a 3k validation set held-out from the test set\n",
    "X_test_texts, X_val_texts, y_test, y_val = train_test_split(\n",
    "                                                X_test_texts,\n",
    "                                                y_test,\n",
    "                                                test_size=3000,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.677\n",
      "Median: 0.600\n",
      "Stdev: 0.231\n",
      "Review length:\n",
      "Mean 157.32 words (stddev: 83.831633)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "\n",
    "print('Mean: %.3f' % np.mean(y_train))\n",
    "print('Median: %.3f' % np.median(y_train))\n",
    "print('Stdev: %.3f' % np.std(y_train))\n",
    "\n",
    "print('Review length:')\n",
    "train_texts_lengths = [len(x.split(' ')) for x in X_train_texts]\n",
    "print(\"Mean %.2f words (stddev: %f)\" % \\\n",
    "      (np.mean(train_texts_lengths),\n",
    "       np.std(train_texts_lengths)))\n",
    "\n",
    "# plot review lengths\n",
    "plt.boxplot(train_texts_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "3000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the texts and keep only the top n words\n",
    "\n",
    "TOP_WORDS = 10000\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=TOP_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_texts)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train_texts)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_texts)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_texts)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bound reviews at 500 words, truncating longer reviews and zero-padding shorter reviews\n",
    "\n",
    "MAX_WORDS = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=MAX_WORDS)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=MAX_WORDS)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_token = {tokenizer.word_index[k]: k for k in tokenizer.word_index.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination_metric(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500, 200)          240800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,561,801\n",
      "Trainable params: 1,561,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 70000 samples, validate on 3000 samples\n",
      "Epoch 1/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0376 - mean_squared_error: 0.0376 - mean_absolute_error: 0.1607 - coeff_determination_metric: 0.2861\n",
      "Epoch 00001: val_loss improved from inf to 0.03375, saving model to ../trained_models/asp2.regress.bs128.nodrop.lstm200.100dimembed.weights.01-0.0337.hdf5\n",
      "70000/70000 [==============================] - 916s 13ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - mean_absolute_error: 0.1607 - coeff_determination_metric: 0.2862 - val_loss: 0.0337 - val_mean_squared_error: 0.0337 - val_mean_absolute_error: 0.1539 - val_coeff_determination_metric: 0.3532\n",
      "Epoch 2/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0312 - mean_squared_error: 0.0312 - mean_absolute_error: 0.1435 - coeff_determination_metric: 0.4065\n",
      "Epoch 00002: val_loss improved from 0.03375 to 0.03214, saving model to ../trained_models/asp2.regress.bs128.nodrop.lstm200.100dimembed.weights.02-0.0321.hdf5\n",
      "70000/70000 [==============================] - 906s 13ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - mean_absolute_error: 0.1435 - coeff_determination_metric: 0.4065 - val_loss: 0.0321 - val_mean_squared_error: 0.0321 - val_mean_absolute_error: 0.1471 - val_coeff_determination_metric: 0.3835\n",
      "Epoch 3/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0258 - mean_squared_error: 0.0258 - mean_absolute_error: 0.1282 - coeff_determination_metric: 0.5095\n",
      "Epoch 00003: val_loss improved from 0.03214 to 0.02969, saving model to ../trained_models/asp2.regress.bs128.nodrop.lstm200.100dimembed.weights.03-0.0297.hdf5\n",
      "70000/70000 [==============================] - 895s 13ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - mean_absolute_error: 0.1281 - coeff_determination_metric: 0.5097 - val_loss: 0.0297 - val_mean_squared_error: 0.0297 - val_mean_absolute_error: 0.1360 - val_coeff_determination_metric: 0.4301\n",
      "Epoch 4/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0225 - mean_squared_error: 0.0225 - mean_absolute_error: 0.1179 - coeff_determination_metric: 0.5707\n",
      "Epoch 00004: val_loss did not improve\n",
      "70000/70000 [==============================] - 867s 12ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - mean_absolute_error: 0.1179 - coeff_determination_metric: 0.5707 - val_loss: 0.0301 - val_mean_squared_error: 0.0301 - val_mean_absolute_error: 0.1338 - val_coeff_determination_metric: 0.4230\n",
      "Epoch 5/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0197 - mean_squared_error: 0.0197 - mean_absolute_error: 0.1085 - coeff_determination_metric: 0.6247\n",
      "Epoch 00005: val_loss improved from 0.02969 to 0.02922, saving model to ../trained_models/asp2.regress.bs128.nodrop.lstm200.100dimembed.weights.05-0.0292.hdf5\n",
      "70000/70000 [==============================] - 886s 13ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - mean_absolute_error: 0.1085 - coeff_determination_metric: 0.6247 - val_loss: 0.0292 - val_mean_squared_error: 0.0292 - val_mean_absolute_error: 0.1327 - val_coeff_determination_metric: 0.4389\n",
      "Epoch 6/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0175 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1011 - coeff_determination_metric: 0.6666\n",
      "Epoch 00006: val_loss did not improve\n",
      "70000/70000 [==============================] - 887s 13ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1011 - coeff_determination_metric: 0.6665 - val_loss: 0.0295 - val_mean_squared_error: 0.0295 - val_mean_absolute_error: 0.1293 - val_coeff_determination_metric: 0.4323\n",
      "Epoch 7/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0155 - mean_squared_error: 0.0155 - mean_absolute_error: 0.0942 - coeff_determination_metric: 0.7044\n",
      "Epoch 00007: val_loss did not improve\n",
      "70000/70000 [==============================] - 880s 13ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - mean_absolute_error: 0.0942 - coeff_determination_metric: 0.7044 - val_loss: 0.0308 - val_mean_squared_error: 0.0308 - val_mean_absolute_error: 0.1321 - val_coeff_determination_metric: 0.4073\n",
      "Epoch 8/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0137 - mean_squared_error: 0.0137 - mean_absolute_error: 0.0878 - coeff_determination_metric: 0.7384\n",
      "Epoch 00008: val_loss did not improve\n",
      "70000/70000 [==============================] - 915s 13ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - mean_absolute_error: 0.0878 - coeff_determination_metric: 0.7385 - val_loss: 0.0316 - val_mean_squared_error: 0.0316 - val_mean_absolute_error: 0.1330 - val_coeff_determination_metric: 0.3931\n",
      "Epoch 9/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0124 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0830 - coeff_determination_metric: 0.7632\n",
      "Epoch 00009: val_loss did not improve\n",
      "70000/70000 [==============================] - 931s 13ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0830 - coeff_determination_metric: 0.7632 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_mean_absolute_error: 0.1340 - val_coeff_determination_metric: 0.3736\n",
      "Epoch 10/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0112 - mean_squared_error: 0.0112 - mean_absolute_error: 0.0784 - coeff_determination_metric: 0.7860\n",
      "Epoch 00010: val_loss did not improve\n",
      "70000/70000 [==============================] - 902s 13ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - mean_absolute_error: 0.0784 - coeff_determination_metric: 0.7860 - val_loss: 0.0332 - val_mean_squared_error: 0.0332 - val_mean_absolute_error: 0.1327 - val_coeff_determination_metric: 0.3591\n",
      "Epoch 11/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0098 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0727 - coeff_determination_metric: 0.8138\n",
      "Epoch 00011: val_loss did not improve\n",
      "70000/70000 [==============================] - 916s 13ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0727 - coeff_determination_metric: 0.8138 - val_loss: 0.0336 - val_mean_squared_error: 0.0336 - val_mean_absolute_error: 0.1334 - val_coeff_determination_metric: 0.3530\n",
      "Epoch 12/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0089 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0691 - coeff_determination_metric: 0.8296\n",
      "Epoch 00012: val_loss did not improve\n",
      "70000/70000 [==============================] - 917s 13ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0691 - coeff_determination_metric: 0.8296 - val_loss: 0.0339 - val_mean_squared_error: 0.0339 - val_mean_absolute_error: 0.1338 - val_coeff_determination_metric: 0.3494\n",
      "Epoch 13/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0652 - coeff_determination_metric: 0.8469\n",
      "Epoch 00013: val_loss did not improve\n",
      "70000/70000 [==============================] - 915s 13ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0652 - coeff_determination_metric: 0.8468 - val_loss: 0.0343 - val_mean_squared_error: 0.0343 - val_mean_absolute_error: 0.1342 - val_coeff_determination_metric: 0.3410\n",
      "Epoch 14/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0627 - coeff_determination_metric: 0.8581\n",
      "Epoch 00014: val_loss did not improve\n",
      "70000/70000 [==============================] - 864s 12ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0627 - coeff_determination_metric: 0.8581 - val_loss: 0.0347 - val_mean_squared_error: 0.0347 - val_mean_absolute_error: 0.1326 - val_coeff_determination_metric: 0.3326\n",
      "Epoch 15/15\n",
      "69888/70000 [============================>.] - ETA: 1s - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0592 - coeff_determination_metric: 0.8734\n",
      "Epoch 00015: val_loss did not improve\n",
      "70000/70000 [==============================] - 876s 13ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0592 - coeff_determination_metric: 0.8734 - val_loss: 0.0342 - val_mean_squared_error: 0.0342 - val_mean_absolute_error: 0.1325 - val_coeff_determination_metric: 0.3416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74b814cf28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM200 model\n",
    "\n",
    "def make_lstm_model(top_words, max_words):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, 100, input_length=max_words))\n",
    "    model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['mse', 'mae', coeff_determination_metric])\n",
    "    return model\n",
    "\n",
    "model = make_lstm_model(TOP_WORDS, MAX_WORDS)\n",
    "print(model.summary())\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../trained_models/asp2.regress.bs128.nodrop.lstm200.100dimembed.weights.{epoch:02d}-{val_loss:.4f}.hdf5',\n",
    "                               verbose=1,\n",
    "                               monitor='val_loss',\n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=15,\n",
    "          batch_size=128,\n",
    "          callbacks=[checkpointer],\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
